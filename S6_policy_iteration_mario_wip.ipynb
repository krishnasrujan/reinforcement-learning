{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy Iteration Mario\n",
    "<p style=\"color:blue;\">\n",
    "By Pramod Sharma : pramod.sharma@prasami.com\n",
    "<p>\n",
    "Dated: 02-Feb- 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgements\n",
    "### Standford University<br>\n",
    "Inspired from: https://github.com/lazyprogrammer/machine_learning_examples/tree/master/rl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.gridWorldGame import standard_grid, negative_grid, print_values, print_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = './images/mario_game.png'>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some basic parameters\n",
    "inpDir = '../input'\n",
    "outDir = '../output'\n",
    "\n",
    "RANDOM_STATE = 24\n",
    "STEPS = 200\n",
    "\n",
    "# parameters for Matplotlib\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "          'figure.figsize': (6, 6),\n",
    "          'axes.labelsize': 'x-large',\n",
    "          'axes.titlesize':'x-large',\n",
    "          'xtick.labelsize':'x-large',\n",
    "          'ytick.labelsize':'x-large'\n",
    "         }\n",
    "\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "\n",
    "SMALL_ENOUGH = 1e-3\n",
    "GAMMA = 0.95\n",
    "ALL_POSSIBLE_ACTIONS = ('U', 'D', 'L', 'R')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to plot the grid\n",
    "\n",
    "def show_grid(val):\n",
    "    plot_grid = np.zeros(12, dtype = np.float).reshape(3,4)\n",
    "    for key in val:\n",
    "        plot_grid[key[0],key[1]] = val[key]\n",
    "    plot_grid[0,3] = 1\n",
    "    plot_grid[1,3] = -1\n",
    "    plot_grid[1,1] = 0\n",
    "    print ( plot_grid)\n",
    "    plt.matshow(plot_grid, cmap = 'RdBu');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rewards:\n",
      "---------------------------\n",
      "-0.10|-0.10|-0.10| 1.00|\n",
      "---------------------------\n",
      "-0.10| 0.00|-0.10|-1.00|\n",
      "---------------------------\n",
      "-0.10|-0.10|-0.10|-0.10|\n"
     ]
    }
   ],
   "source": [
    "# Lets create a Grid for our Mario\n",
    "grid = negative_grid()\n",
    "print(\"Rewards:\")\n",
    "print_values(grid.rewards, grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Keys: dict_keys([(0, 0), (0, 1), (0, 2), (1, 0), (1, 2), (2, 0), (2, 1), (2, 2), (2, 3)])\n"
     ]
    }
   ],
   "source": [
    "# Note: Grid Action keys are defined along with the grid\n",
    "# What are the keys?\n",
    "print (\"Action Keys:\", grid.actions.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 0): ('D', 'R'),\n",
       " (0, 1): ('L', 'R'),\n",
       " (0, 2): ('L', 'D', 'R'),\n",
       " (1, 0): ('U', 'D'),\n",
       " (1, 2): ('U', 'D', 'R'),\n",
       " (2, 0): ('U', 'R'),\n",
       " (2, 1): ('L', 'R'),\n",
       " (2, 2): ('L', 'R', 'U'),\n",
       " (2, 3): ('L', 'U')}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What actions are possible at each of the location???\n",
    "\n",
    "grid.actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = './images/mario_game.png' style=\"width:300px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: No action defined for terminal state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Policies for these actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial policy:\n",
      "---------------------------\n",
      "  R  |  D  |  D  |     |\n",
      "---------------------------\n",
      "  R  |     |  D  |     |\n",
      "---------------------------\n",
      "  U  |  D  |  L  |  R  |\n"
     ]
    }
   ],
   "source": [
    "# Let's Define a Dict for policy\n",
    "policy = {}\n",
    "for s in grid.actions.keys():\n",
    "    policy[s] = np.random.choice(ALL_POSSIBLE_ACTIONS)\n",
    "    \n",
    "# initial policy\n",
    "print(\"Initial policy:\")\n",
    "print_policy(policy, grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States: {(0, 0), (1, 3), (2, 1), (2, 3), (1, 0), (0, 3), (0, 1), (1, 2), (2, 0), (2, 2), (0, 2)}\n"
     ]
    }
   ],
   "source": [
    "states = grid.all_states()\n",
    "print ('States:', states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actions: {(0, 0): ('D', 'R'), (0, 1): ('L', 'R'), (0, 2): ('L', 'D', 'R'), (1, 0): ('U', 'D'), (1, 2): ('U', 'D', 'R'), (2, 0): ('U', 'R'), (2, 1): ('L', 'R'), (2, 2): ('L', 'R', 'U'), (2, 3): ('L', 'U')}\n"
     ]
    }
   ],
   "source": [
    "print ('Actions:', grid.actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      " 0.36| 0.37| 0.24| 0.00|\n",
      "---------------------------\n",
      " 0.73| 0.00| 0.17| 0.00|\n",
      "---------------------------\n",
      " 0.01| 0.99| 0.34| 0.59|\n"
     ]
    }
   ],
   "source": [
    "# Initialize V(s) - value function\n",
    "# Again a dict with keys as states\n",
    "# Random initialization of all Values where action is needed\n",
    "# zero for terminal states\n",
    "V = {}\n",
    "\n",
    "for s in states:\n",
    "    \n",
    "    if s in grid.actions:\n",
    "        V[s] = np.random.random()\n",
    "    else:\n",
    "        V[s] = 0\n",
    "\n",
    "# Initial value for all states in grid\n",
    "# print(V)\n",
    "print_values(V, grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.36332355  0.36957489  0.23863538  1.        ]\n",
      " [ 0.72825602  0.          0.16870283 -1.        ]\n",
      " [ 0.00862727  0.98954306  0.34246636  0.58764994]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdwAAAF1CAYAAABCsFvTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAMHElEQVR4nO3db8jvd13H8dd7ncziDE9z4lZCC7xhdWc3Dgpqyz83XKukxDveKCRohiXhnBkm5fxXITUNiTXGxCTvdEMGKiOkEl2LdqJloBhWG0iumnPD0XHo+nTjnGBdTM7vOuf8Xr+u33k84HDt+l7XftcLvofzvL6/P9c1a60AANt12a4HAMClQHABoEBwAaBAcAGgQHABoEBwAaBAcAGgQHDPw8zcMDP3z8wTM/PAzNy0601sZmaum5m7ZubBmVkz845db2IzM/PWmbl3Zr4+M4/OzOdm5vpd7+LcZubnZ+bvzp670zPzxZl5y8zMrrc1Hdv1gKNmZk4muSvJ7yd5XZIXJbltZv5rrXXbTsexieNJvpDkY0k+sOMtHM4rktyZ5L4kp5P8UpJPzMxPrLXu2ekyzuU/krw7yZeSPJHkx5P8UZJvJ/ngDndVjZ80dTgz87Ek16y1XvyUY+9P8tq11g/vbhmHNTMPJLljrfWeXW/h/MzMPyb587XWW3a9hcOZmY8nyVrr53a9pcVdyof3kiR3Hzh2d5JrZuZ5O9gDl6SZuSzJ5Uke3vUWNjdnvDBn/i39y13vaRLcw7s6yUMHjj30lI8BHW9PciLJR3c9hHObmWfNzOM5c5fyvUk+tNb6wx3PqvIY7sXl/nkomJk35kxwX73W+squ97CRbyS5Nsn3JXlxkt+ZmX9ba92x21k9gnt4X01y1YFjzz379uCVL3CRzczNSW7Jmdh+etd72Mxa67+TfPnsu5+fme9P8p4kl0xw3aV8ePckedWBY9cnedB32rBdM/OuJL+d5AaxPfIuS/I9ux7R5Ar38G5N8tcz896ceezohUnelOTNO13FRmbmeJLnn333GUmumplrkzy+1vryd/4/2bWZ+UCSN+TMy/G+NDP/e0/T6bXWY7tbxrnMzC1JPpvkX5J8d5LrkrwtyYd3uavNy4LOw8z8VJL3JXlBztyN/MG11h/sdhWbmJmX5emfGfmZtdbLums4jJn5Tv9YfWSt9frmFg5nZm5N8jNJfjDJN3MmvHcmuW2t9eQutzUJLgAUeAwXAAoEFwAKBBcACgQXAAoEFwAKBBcACgT3AszMjbvewPlz/o4u5+5ou1TPn+BemEvyL80ecf6OLufuaLskz5/gAkDBVn/S1OUnrljPvnp/fyf7448+kuMnrtj1DM7TNx59JJfv6fl75rH9/l760Ue+lhNXPHvXM7bmn/55v38Pyvr2NzPHnrnrGVuzTn/t4bXWcw4e3+ovL3j21c/Lb/3JJ7b5JdiiJ/3YzyPrR59zfNcTuAAvf81bdz2BC/Ct+z/84NMd3+9vgwHg/wnBBYACwQWAAsEFgALBBYACwQWAAsEFgALBBYACwQWAAsEFgALBBYACwQWAAsEFgALBBYACwQWAAsEFgALBBYACwQWAAsEFgALBBYACwQWAAsEFgALBBYACwQWAAsEFgALBBYACwQWAAsEFgALBBYACwQWAAsEFgALBBYACwQWAAsEFgALBBYACwQWAAsEFgALBBYACwQWAAsEFgALBBYACwQWAAsEFgALBBYACwQWAAsEFgALBBYACwQWAAsEFgALBBYCCjYI7MzfMzP0z88TMPDAzN217GADsk3MGd2ZOJrkryd1Jrk3yziTvm5lf3u40ANgfxzb4nJuS3LfW+o2z739xZn4syduS3La1ZQCwRza5S/klOXN1+1R3J7lmZp538JNn5saZOTUzpx5/9JGLsREAjrxNgnt1kocOHHvoKR/7P9Zat6+1Tq61Th4/ccWF7gOAvXChz1JeF2UFAOy5TYL71SRXHTj23LNvD175AgBPY5Pg3pPkVQeOXZ/kwbXWVy7+JADYP5sE99YkL5yZ987MC2bmF5K8KcnvbncaAOyPcwZ3rXVfkp9N8tNJ/iHJu5P85lrLS4IAYEObvA43a61PJvnklrcAwN7ys5QBoEBwAaBAcAGgQHABoEBwAaBAcAGgQHABoEBwAaBAcAGgQHABoEBwAaBAcAGgQHABoEBwAaBAcAGgQHABoEBwAaBAcAGgQHABoEBwAaBAcAGgQHABoEBwAaBAcAGgQHABoEBwAaBAcAGgQHABoEBwAaBAcAGgQHABoEBwAaBAcAGgQHABoEBwAaBAcAGgQHABoEBwAaBAcAGgQHABoEBwAaBAcAGgQHABoEBwAaBAcAGgQHABoEBwAaDg2DZv/N+/fjq3/tnnt/kl2KK/veWVu57AeXrgsW/tegIX4Bfv/4tdT+AC/PF3OO4KFwAKBBcACgQXAAoEFwAKBBcACgQXAAoEFwAKBBcACgQXAAoEFwAKBBcACgQXAAoEFwAKBBcACgQXAAoEFwAKBBcACgQXAAoEFwAKBBcACgQXAAoEFwAKBBcACgQXAAoEFwAKBBcACgQXAAoEFwAKBBcACgQXAAoEFwAKBBcACgQXAAoEFwAKBBcACgQXAAoEFwAKBBcACgQXAAoEFwAKBBcACgQXAAoEFwAKBBcACgQXAAoEFwAKBBcACgQXAAoEFwAKBBcACgQXAAoEFwAKNgruzFw3M3fNzIMzs2bmHdseBgD7ZNMr3ONJvpDk15M8tL05ALCfjm3ySWutTyX5VJLMzO9tdREA7CGP4QJAwUUP7szcODOnZubUk6cfu9g3DwBH0kUP7lrr9rXWybXWye/63mdd7JsHgCPJXcoAUCC4AFCw0bOUZ+Z4kuefffcZSa6amWuTPL7W+vK2xgHAvtj0Cvdkkr8/++fqJL9y9r/v2NIuANgrm74O96+SzHanAMD+8hguABQILgAUCC4AFAguABQILgAUCC4AFAguABQILgAUCC4AFAguABQILgAUCC4AFAguABQILgAUCC4AFAguABQILgAUCC4AFAguABQILgAUCC4AFAguABQILgAUCC4AFAguABQILgAUCC4AFAguABQILgAUCC4AFAguABQILgAUCC4AFAguABQILgAUCC4AFAguABQILgAUCC4AFAguABQILgAUCC4AFAguABQILgAUCC4AFAguABQILgAUCC4AFBzb5o3/yA9cns++85Xb/BJs0YmXvmnXEzhPd97xzl1P4AL864f+dNcTuBC/+tKnPewKFwAKBBcACgQXAAoEFwAKBBcACgQXAAoEFwAKBBcACgQXAAoEFwAKBBcACgQXAAoEFwAKBBcACgQXAAoEFwAKBBcACgQXAAoEFwAKBBcACgQXAAoEFwAKBBcACgQXAAoEFwAKBBcACgQXAAoEFwAKBBcACgQXAAoEFwAKBBcACgQXAAoEFwAKBBcACgQXAAoEFwAKBBcACgQXAAoEFwAKBBcACgQXAAoEFwAKBBcACgQXAAoEFwAKBBcACgQXAAoEFwAKBBcACgQXAAoEFwAKzhncmXnrzNw7M1+fmUdn5nMzc31jHADsi02ucF+R5M4kL0/yoiR/k+QTM/OSbQ4DgH1y7FyfsNb6yQOHbp6ZVyV5TZJ7trIKAPbMoR/DnZnLklye5OGLPwcA9tP5PGnq7UlOJPno031wZm6cmVMzc+rhhzUZAJJDBndm3pgzwX3tWusrT/c5a63b11on11onr7zyyouxEQCOvI2DOzM3J3l/klevtT69vUkAsH/O+aSpJJmZdyV5c5Ib1lqf2e4kANg/5wzuzHwgyRuSvC7Jl2bmqrMfOr3Wemyb4wBgX2xyhftrZ99+/MDxjyR5/UVdAwB7apPX4U5jCADsMz9LGQAKBBcACgQXAAoEFwAKBBcACgQXAAoEFwAKBBcACgQXAAoEFwAKBBcACgQXAAoEFwAKBBcACgQXAAoEFwAKBBcACgQXAAoEFwAKBBcACgQXAAoEFwAKBBcACgQXAAoEFwAKBBcACgQXAAoEFwAKBBcACgQXAAoEFwAKBBcACgQXAAoEFwAKBBcACgQXAAoEFwAKBBcACgQXAAoEFwAKBBcACgQXAAoEFwAKBBcACgQXAAoEFwAKBBcACgQXAApmrbW9G5/5zyQPbu0L7N6VSR7e9QjOm/N3dDl3R9u+n78fWms95+DBrQZ3383MqbXWyV3v4Pw4f0eXc3e0Xarnz13KAFAguABQILgX5vZdD+CCOH9Hl3N3tF2S589juABQ4AoXAAoEFwAKBBcACgQXAAoEFwAK/gft4aJVdV9nUQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_grid(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 0): 'R', (0, 1): 'D', (0, 2): 'D', (1, 0): 'R', (1, 2): 'D', (2, 0): 'U', (2, 1): 'D', (2, 2): 'L', (2, 3): 'R'}\n"
     ]
    }
   ],
   "source": [
    "print(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 0): 0.3633235480691501, (1, 3): 0, (2, 1): 0.9895430633476594, (2, 3): 0.587649942340769, (1, 0): 0.7282560158539026, (0, 3): 0, (0, 1): 0.3695748937751083, (1, 2): 0.1687028317616236, (2, 0): 0.008627273332389662, (2, 2): 0.3424663597807085, (0, 2): 0.23863537627264275}\n"
     ]
    }
   ],
   "source": [
    "print(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "values 1: \n",
      "---------------------------\n",
      " 0.36| 0.37| 0.24| 0.00|\n",
      "---------------------------\n",
      " 0.73| 0.00| 0.17| 0.00|\n",
      "---------------------------\n",
      " 0.01| 0.99| 0.34| 0.59|\n",
      "policy 1: \n",
      "---------------------------\n",
      "  R  |  D  |  D  |     |\n",
      "---------------------------\n",
      "  R  |     |  D  |     |\n",
      "---------------------------\n",
      "  U  |  D  |  L  |  R  |\n",
      "values 2: \n",
      "---------------------------\n",
      "-1.99|-1.99|-1.98| 0.00|\n",
      "---------------------------\n",
      "-1.98| 0.00|-1.98| 0.00|\n",
      "---------------------------\n",
      "-1.98|-1.98|-1.98|-1.98|\n",
      "policy 2: \n",
      "---------------------------\n",
      "  D  |  R  |  R  |     |\n",
      "---------------------------\n",
      "  L  |     |  R  |     |\n",
      "---------------------------\n",
      "  R  |  U  |  L  |  U  |\n",
      "values 3: \n",
      "---------------------------\n",
      "-1.99| 0.85| 1.00| 0.00|\n",
      "---------------------------\n",
      "-1.99| 0.00|-1.00| 0.00|\n",
      "---------------------------\n",
      "-1.98|-1.98|-1.98|-1.00|\n",
      "policy 3: \n",
      "---------------------------\n",
      "  R  |  R  |  R  |     |\n",
      "---------------------------\n",
      "  D  |     |  U  |     |\n",
      "---------------------------\n",
      "  R  |  U  |  U  |  U  |\n",
      "values 4: \n",
      "---------------------------\n",
      " 0.71| 0.85| 1.00| 0.00|\n",
      "---------------------------\n",
      "-1.99| 0.00| 0.85| 0.00|\n",
      "---------------------------\n",
      "-1.99|-1.99| 0.71|-1.00|\n",
      "policy 4: \n",
      "---------------------------\n",
      "  R  |  R  |  R  |     |\n",
      "---------------------------\n",
      "  U  |     |  U  |     |\n",
      "---------------------------\n",
      "  R  |  R  |  U  |  L  |\n",
      "values 5: \n",
      "---------------------------\n",
      " 0.71| 0.85| 1.00| 0.00|\n",
      "---------------------------\n",
      " 0.57| 0.00| 0.85| 0.00|\n",
      "---------------------------\n",
      " 0.44| 0.57| 0.71| 0.57|\n",
      "policy 5: \n",
      "---------------------------\n",
      "  R  |  R  |  R  |     |\n",
      "---------------------------\n",
      "  U  |     |  U  |     |\n",
      "---------------------------\n",
      "  U  |  R  |  U  |  L  |\n"
     ]
    }
   ],
   "source": [
    "iter = 0\n",
    "# Policy Iterations till convergence \n",
    "while True:\n",
    "    iter += 1\n",
    "    \n",
    "    #################################\n",
    "    #    Printing Values amd Policy #\n",
    "    #################################\n",
    "    print(\"values %d: \" % iter)\n",
    "    print_values(V, grid)\n",
    "    print(\"policy %d: \" % iter)\n",
    "    print_policy(policy, grid)\n",
    "    ##########################\n",
    "    # policy evaluation step #\n",
    "    ##########################\n",
    "    while True:\n",
    "        biggest_change = 0\n",
    "        for s in states:\n",
    "            old_v = V[s]\n",
    "\n",
    "            # V(s) only has value if it's not a terminal state\n",
    "            if s in policy:\n",
    "                \n",
    "                a = policy[s] # pick action from the policy\n",
    "                grid.set_state(s) # Pick the point of this state, current_state returns this value\n",
    "                r = grid.move(a) #  Make the move and get the Reward\n",
    "                #print(s,grid.current_state())\n",
    "                V[s] = r + GAMMA * V[grid.current_state()] # get Value for current location and \n",
    "                # returns value of next state \n",
    "                biggest_change = max(biggest_change, np.abs(old_v - V[s]))\n",
    "\n",
    "        if biggest_change < SMALL_ENOUGH:\n",
    "            break\n",
    "\n",
    "    # policy improvement step\n",
    "    is_policy_converged = True\n",
    "    for s in states:\n",
    "        if s in policy:\n",
    "            old_a = policy[s]\n",
    "            new_a = None\n",
    "            best_value = -np.inf\n",
    "            # loop through all possible actions to find the best current action\n",
    "            for a in ALL_POSSIBLE_ACTIONS:\n",
    "                grid.set_state(s)\n",
    "                r = grid.move(a)\n",
    "                v = r + GAMMA * V[grid.current_state()]\n",
    "                if v > best_value:\n",
    "                    best_value = v\n",
    "                    new_a = a\n",
    "            policy[s] = new_a  # updating policy of a state where the move has highest v.\n",
    "            if new_a != old_a:\n",
    "                is_policy_converged = False\n",
    "\n",
    "    if is_policy_converged:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final values:\n",
      "---------------------------\n",
      " 0.71| 0.85| 1.00| 0.00|\n",
      "---------------------------\n",
      " 0.57| 0.00| 0.85| 0.00|\n",
      "---------------------------\n",
      " 0.44| 0.57| 0.71| 0.57|\n",
      "final policy:\n",
      "---------------------------\n",
      "  R  |  R  |  R  |     |\n",
      "---------------------------\n",
      "  U  |     |  U  |     |\n",
      "---------------------------\n",
      "  U  |  R  |  U  |  L  |\n",
      "[[ 0.7075      0.85        1.          1.        ]\n",
      " [ 0.572125    0.          0.85       -1.        ]\n",
      " [ 0.44351875  0.572125    0.7075      0.572125  ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"final values:\")\n",
    "print_values(V, grid)\n",
    "print(\"final policy:\")\n",
    "print_policy(policy, grid)\n",
    "show_grid(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
