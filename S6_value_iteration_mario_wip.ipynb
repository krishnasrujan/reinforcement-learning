{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Value Iteration Mario\n",
    "<p style=\"color:blue;\">\n",
    "By Pramod Sharma : pramod.sharma@prasami.com\n",
    "<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgements\n",
    "### Standford University<br>\n",
    "Inspired from: https://github.com/lazyprogrammer/machine_learning_examples/tree/master/rl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.gridWorldGame import standard_grid, negative_grid,print_values, print_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = './images/mario_game.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some basic parameters\n",
    "inpDir = '../input'\n",
    "outDir = '../output'\n",
    "\n",
    "RANDOM_STATE = 24\n",
    "STEPS = 200\n",
    "\n",
    "# parameters for Matplotlib\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "          'figure.figsize': (9, 6),\n",
    "          'axes.labelsize': 'x-large',\n",
    "          'axes.titlesize':'x-large',\n",
    "          'xtick.labelsize':'x-large',\n",
    "          'ytick.labelsize':'x-large'\n",
    "         }\n",
    "\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "\n",
    "SMALL_ENOUGH = 1e-3\n",
    "GAMMA = 0.95\n",
    "ALL_POSSIBLE_ACTIONS = ('U', 'D', 'L', 'R')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to plot the grid\n",
    "\n",
    "def show_grid(val):\n",
    "    plot_grid = np.zeros(12, dtype = np.float).reshape(3,4)\n",
    "    for key in val:\n",
    "        plot_grid[key[0],key[1]] = val[key]\n",
    "    plot_grid[0,3] = 1\n",
    "    plot_grid[1,3] = -1\n",
    "    plot_grid[1,1] = 0\n",
    "    print ( plot_grid)\n",
    "    plt.matshow(plot_grid, cmap = 'RdBu');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rewards:\n",
      "---------------------------\n",
      "-0.10|-0.10|-0.10| 1.00|\n",
      "---------------------------\n",
      "-0.10| 0.00|-0.10|-1.00|\n",
      "---------------------------\n",
      "-0.10|-0.10|-0.10|-0.10|\n"
     ]
    }
   ],
   "source": [
    "# Lets create a Grid for our Mario\n",
    "grid = negative_grid()\n",
    "print(\"Rewards:\")\n",
    "print_values(grid.rewards, grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Keys: dict_keys([(0, 0), (0, 1), (0, 2), (1, 0), (1, 2), (2, 0), (2, 1), (2, 2), (2, 3)])\n"
     ]
    }
   ],
   "source": [
    "# Note: Grid Action keys are defined along with the grid\n",
    "# What are the keys?\n",
    "print (\"Action Keys:\", grid.actions.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: No action defined for terminal state\n",
    "## Define Policies for these actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial policy:\n",
      "---------------------------\n",
      "  R  |  D  |  L  |     |\n",
      "---------------------------\n",
      "  D  |     |  D  |     |\n",
      "---------------------------\n",
      "  D  |  L  |  D  |  R  |\n"
     ]
    }
   ],
   "source": [
    "# Lets Define a Dict for policy\n",
    "policy = {}\n",
    "for s in grid.actions.keys():\n",
    "    policy[s] = np.random.choice(ALL_POSSIBLE_ACTIONS)\n",
    "    \n",
    "# initial policy\n",
    "print(\"Initial policy:\")\n",
    "print_policy(policy, grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States: {(0, 0), (1, 3), (2, 1), (2, 3), (1, 0), (0, 3), (0, 1), (1, 2), (2, 0), (2, 2), (0, 2)}\n"
     ]
    }
   ],
   "source": [
    "states = grid.all_states()\n",
    "print ('States:', states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 0): 'R',\n",
       " (0, 1): 'D',\n",
       " (0, 2): 'L',\n",
       " (1, 0): 'D',\n",
       " (1, 2): 'D',\n",
       " (2, 0): 'D',\n",
       " (2, 1): 'L',\n",
       " (2, 2): 'D',\n",
       " (2, 3): 'R'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      " 0.74| 0.80| 0.78| 0.00|\n",
      "---------------------------\n",
      " 0.71| 0.00| 0.77| 0.00|\n",
      "---------------------------\n",
      " 0.55| 0.85| 0.00| 0.95|\n",
      "[[ 0.73534366  0.80465133  0.77876521  1.        ]\n",
      " [ 0.70571195  0.          0.76608813 -1.        ]\n",
      " [ 0.55298907  0.84936807  0.00278165  0.95451741]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize V(s) - value function\n",
    "# Again a dict with keys as states\n",
    "# Random initialization of all Values where action is needed\n",
    "# zero for terminal states\n",
    "V = {}\n",
    "\n",
    "for s in states:\n",
    "    \n",
    "    if s in grid.actions:\n",
    "        V[s] = np.random.random()\n",
    "    else:\n",
    "        V[s] = 0\n",
    "\n",
    "# Initial value for all states in grid\n",
    "# print(V)\n",
    "print_values(V, grid)\n",
    "show_grid(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "values 1: \n",
      "---------------------------\n",
      " 0.74| 0.80| 0.78| 0.00|\n",
      "---------------------------\n",
      " 0.71| 0.00| 0.77| 0.00|\n",
      "---------------------------\n",
      " 0.55| 0.85| 0.00| 0.95|\n",
      "policy 1: \n",
      "---------------------------\n",
      "  L  |  U  |  R  |     |\n",
      "---------------------------\n",
      "  L  |     |  R  |     |\n",
      "---------------------------\n",
      "  R  |  L  |  L  |  U  |\n",
      "values 2: \n",
      "---------------------------\n",
      " 0.60| 0.66| 1.00| 0.00|\n",
      "---------------------------\n",
      " 0.60| 0.00| 0.64| 0.00|\n",
      "---------------------------\n",
      " 0.57| 0.71| 0.81| 0.81|\n",
      "policy 2: \n",
      "---------------------------\n",
      "  L  |  U  |  R  |     |\n",
      "---------------------------\n",
      "  L  |     |  R  |     |\n",
      "---------------------------\n",
      "  R  |  L  |  L  |  U  |\n",
      "values 3: \n",
      "---------------------------\n",
      " 0.71| 0.85| 1.00| 0.00|\n",
      "---------------------------\n",
      " 0.47| 0.00| 0.85| 0.00|\n",
      "---------------------------\n",
      " 0.53| 0.67| 0.71| 0.67|\n",
      "policy 3: \n",
      "---------------------------\n",
      "  L  |  U  |  R  |     |\n",
      "---------------------------\n",
      "  L  |     |  R  |     |\n",
      "---------------------------\n",
      "  R  |  L  |  L  |  U  |\n",
      "values 4: \n",
      "---------------------------\n",
      " 0.71| 0.85| 1.00| 0.00|\n",
      "---------------------------\n",
      " 0.57| 0.00| 0.85| 0.00|\n",
      "---------------------------\n",
      " 0.44| 0.57| 0.71| 0.57|\n",
      "policy 4: \n",
      "---------------------------\n",
      "  L  |  U  |  R  |     |\n",
      "---------------------------\n",
      "  L  |     |  R  |     |\n",
      "---------------------------\n",
      "  R  |  L  |  L  |  U  |\n",
      "values:\n",
      "---------------------------\n",
      " 0.71| 0.85| 1.00| 0.00|\n",
      "---------------------------\n",
      " 0.57| 0.00| 0.85| 0.00|\n",
      "---------------------------\n",
      " 0.44| 0.57| 0.71| 0.57|\n",
      "policy:\n",
      "---------------------------\n",
      "  R  |  R  |  R  |     |\n",
      "---------------------------\n",
      "  U  |     |  U  |     |\n",
      "---------------------------\n",
      "  U  |  R  |  U  |  L  |\n"
     ]
    }
   ],
   "source": [
    "# All changes from the policy iterations will be imployed here\n",
    "# repeat until convergence\n",
    "# V[s] = max[a]{ sum[s',r] { p(s',r|s,a)[r + gamma*V[s']] } }\n",
    "\n",
    "iter = 0\n",
    "\n",
    "while True:\n",
    "    iter += 1\n",
    "    print(\"values %d: \" % iter)\n",
    "    print_values(V, grid)\n",
    "    print(\"policy %d: \" % iter)\n",
    "    print_policy(policy, grid)\n",
    "      \n",
    "    biggest_change = 0\n",
    "    for s in states:\n",
    "        old_v = V[s]\n",
    "\n",
    "        # V(s) only has value if it's not a terminal state\n",
    "        if s in policy:\n",
    "            new_v = -np.inf\n",
    "            for a in ALL_POSSIBLE_ACTIONS:\n",
    "                grid.set_state(s) # Pick the point of this state \n",
    "                r = grid.move(a) # Get the Reward\n",
    "                v = r + GAMMA * V[grid.current_state()] # get Value for current location and\n",
    "                if v > new_v:\n",
    "                    new_v = v\n",
    "            V[s] = new_v\n",
    "            \n",
    "            biggest_change = max(biggest_change, np.abs(old_v - V[s]))\n",
    "\n",
    "    if biggest_change < SMALL_ENOUGH:\n",
    "        break\n",
    "        \n",
    "# find a policy that leads to optimal value function\n",
    "for s in policy.keys():\n",
    "    best_a = None\n",
    "    best_value = -np.inf\n",
    "    # loop through all possible actions to find the best current action\n",
    "    for a in ALL_POSSIBLE_ACTIONS:\n",
    "        grid.set_state(s)\n",
    "        r = grid.move(a)\n",
    "        v = r + GAMMA * V[grid.current_state()]\n",
    "        if v > best_value:\n",
    "            best_value = v\n",
    "            best_a = a\n",
    "    policy[s] = best_a\n",
    "\n",
    "# our goal here is to verify that we get the same answer as with policy iteration\n",
    "print(\"values:\")\n",
    "print_values(V, grid)\n",
    "print(\"policy:\")\n",
    "print_policy(policy, grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.7075      0.85        1.          1.        ]\n",
      " [ 0.572125    0.          0.85       -1.        ]\n",
      " [ 0.44351875  0.572125    0.7075      0.572125  ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_grid(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
